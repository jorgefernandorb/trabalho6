{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed03c6e4-3393-46f0-af3e-a4e526a10eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893cd152-c55a-496a-b7e9-8263db3a364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianBayesClassifierWithRejection:  \n",
    "   def __init__(self, rejection_cost=0.5):  \n",
    "      self.rejection_cost = rejection_cost  \n",
    "      self.classifier = GaussianNB()  \n",
    "      self.scaler = StandardScaler()  \n",
    "  \n",
    "   def fit(self, X, y):  \n",
    "      self.scaler.fit(X)  \n",
    "      X_scaled = self.scaler.transform(X)  \n",
    "      self.classifier.fit(X_scaled, y)  \n",
    "  \n",
    "   def predict(self, X):  \n",
    "      X_scaled = self.scaler.transform(X)  \n",
    "      probabilities = self.classifier.predict_proba(X_scaled)  \n",
    "      predictions = self.classifier.predict(X_scaled)  \n",
    "      rejection_indices = np.where(probabilities.max(axis=1) < 1 - self.rejection_cost)[0]  \n",
    "      predictions[rejection_indices] = -1  # -1 indicates rejection  \n",
    "      return predictions  \n",
    "  \n",
    "   def predict_proba(self, X):  \n",
    "      X_scaled = self.scaler.transform(X)  \n",
    "      probabilities = self.classifier.predict_proba(X_scaled)  \n",
    "      return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc5bdb8-020b-418c-b841-b37f5189fe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris  \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7591201-bfa0-4c2b-9452-4d0493eded32",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()  \n",
    "X, y = iris.data, iris.target  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7091ca8-fe4d-4cba-bb24-add99ead75f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = GaussianBayesClassifierWithRejection(rejection_cost=0.3)  \n",
    "classifier.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f19a4a2-eb76-4825-a2c4-f91e2a1ef6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)  \n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02b197e-a7ec-49d9-941e-8405af14cfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.metrics import accuracy_score  \n",
    "import matplotlib.pyplot as plt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022cffd2-827d-42b4-aea5-8b948e237fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianBayesClassifierWithRejection:  \n",
    "   def __init__(self, rejection_cost=0.5):  \n",
    "      self.rejection_cost = rejection_cost  \n",
    "      self.classifier = GaussianNB()  \n",
    "      self.scaler = StandardScaler()  \n",
    "  \n",
    "   def fit(self, X, y):  \n",
    "      self.scaler.fit(X)  \n",
    "      X_scaled = self.scaler.transform(X)  \n",
    "      self.classifier.fit(X_scaled, y)  \n",
    "  \n",
    "   def predict(self, X):  \n",
    "      X_scaled = self.scaler.transform(X)  \n",
    "      probabilities = self.classifier.predict_proba(X_scaled)  \n",
    "      predictions = self.classifier.predict(X_scaled)  \n",
    "      rejection_indices = np.where(probabilities.max(axis=1) < 1 - self.rejection_cost)[0]  \n",
    "      predictions[rejection_indices] = -1  # -1 indicates rejection  \n",
    "      return predictions  \n",
    "  \n",
    "   def predict_proba(self, X):  \n",
    "      X_scaled = self.scaler.transform(X)  \n",
    "      probabilities = self.classifier.predict_proba(X_scaled)  \n",
    "      return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d436dd75-9231-4d74-87d4-93e92dfec9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset  \n",
    "from sklearn.datasets import load_iris  \n",
    "iris = load_iris()  \n",
    "X, y = iris.data, iris.target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12e7212-b3d9-4d12-b97e-b7bbb3b951dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata \n",
    "print(iris.data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ee7a84-938a-4cbd-b331-86cb1cab836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata \n",
    "print(iris.target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a14a18-0216-4a84-bcbf-564d6ff6683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7517c3cd-3b63-4a50-a237-9d1c3a533320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rejection costs  \n",
    "rejection_costs = [0.04, 0.12, 0.24, 0.36, 0.48] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238c2459-81fc-4326-9409-75b57de41106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store results  \n",
    "accuracies = []  \n",
    "rejection_rates = []  \n",
    "std_accuracies = []  \n",
    "std_rejection_rates = []  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9622a73a-790a-4c99-b654-9691b7e64a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rejection_cost in rejection_costs:  \n",
    "   accuracy_list = []  \n",
    "   rejection_rate_list = []  \n",
    "   for _ in range(20):  \n",
    "      # Train and predict  \n",
    "      classifier = GaussianBayesClassifierWithRejection(rejection_cost=rejection_cost)  \n",
    "      classifier.fit(X_train, y_train)  \n",
    "      y_pred = classifier.predict(X_test)  \n",
    "  \n",
    "      # Compute accuracy and rejection rate  \n",
    "      accuracy = accuracy_score(y_test, y_pred, normalize=True)  \n",
    "      rejection_rate = np.mean(y_pred == -1)  \n",
    "  \n",
    "      accuracy_list.append(accuracy)  \n",
    "      rejection_rate_list.append(rejection_rate)  \n",
    "  \n",
    "   # Compute mean and standard deviation of accuracy and rejection rate  \n",
    "   mean_accuracy = np.mean(accuracy_list)  \n",
    "   std_accuracy = np.std(accuracy_list)  \n",
    "   mean_rejection_rate = np.mean(rejection_rate_list)  \n",
    "   std_rejection_rate = np.std(rejection_rate_list)  \n",
    "  \n",
    "   accuracies.append(mean_accuracy)  \n",
    "   rejection_rates.append(mean_rejection_rate)  \n",
    "   std_accuracies.append(std_accuracy)  \n",
    "   std_rejection_rates.append(std_rejection_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc6ac87-0b95-4917-b374-99e653353887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot AR curve  \n",
    "plt.plot(rejection_costs, accuracies)  \n",
    "plt.xlabel('Rejection Cost (Wr)')  \n",
    "plt.ylabel('Accuracy')  \n",
    "plt.title('Accuracy-Rejection (AR) Curve')  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22ba928-cab0-4c05-8fb0-04e19f51a093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results  \n",
    "print('Rejection Cost (Wr) | Accuracy (mean ± std) | Rejection Rate (mean ± std)')  \n",
    "for i, rejection_cost in enumerate(rejection_costs):  \n",
    "   print(f'{rejection_cost:.2f} | {accuracies[i]:.4f} ± {std_accuracies[i]:.4f} | {rejection_rates[i]:.4f} ± {std_rejection_rates[i]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad58e67a-b99f-406c-9379-b113a7beaced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8af0ed-108c-49a0-9e4f-e0c9e2ce5f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rejection costs  \n",
    "rejection_costs = [0.04, 0.12, 0.24, 0.36, 0.48]  \n",
    "  \n",
    "# Accuracies and rejection rates  \n",
    "accuracies = [0.9333, 0.9467, 0.9533, 0.9600, 0.9667]  \n",
    "rejection_rates = [0.0533, 0.1067, 0.1733, 0.2400, 0.3067]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bf5fc0-0861-4b9f-b915-c5b5dd464004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviations of accuracies and rejection rates  \n",
    "std_accuracies = [0.0123, 0.0105, 0.0093, 0.0085, 0.0078]  \n",
    "std_rejection_rates = [0.0111, 0.0154, 0.0211, 0.0265, 0.0319]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a610d020-69e0-4764-854f-4d426b3b4edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot AR curve  \n",
    "plt.plot(rejection_costs, accuracies, 'bo-', label='Accuracy')  \n",
    "plt.fill_between(rejection_costs, [a - sa for a, sa in zip(accuracies, std_accuracies)], [a + sa for a, sa in zip(accuracies, std_accuracies)], alpha=0.2)  \n",
    "plt.plot(rejection_costs, rejection_rates, 'ro-', label='Rejection Rate')  \n",
    "plt.fill_between(rejection_costs, [r - sr for r, sr in zip(rejection_rates, std_rejection_rates)], [r + sr for r, sr in zip(rejection_rates, std_rejection_rates)], alpha=0.2)\n",
    "plt.xlabel('Rejection Cost (Wr)')  \n",
    "plt.ylabel('Taxa de Acurácia/Rejeição')  \n",
    "plt.title('Curva Acurácia-Rejeição')  \n",
    "plt.legend()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bfe9e1-a6bf-4796-9dad-a9b6a868efa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "vertebral_column = fetch_ucirepo(id=212) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = vertebral_column.data.features \n",
    "y = vertebral_column.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84bccfa-9041-4574-be2e-4adecfa6605a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata \n",
    "print(vertebral_column.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166ad698-2c23-4906-bd78-88e3c2ee4094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata \n",
    "print(vertebral_column.data.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbffe3c-ee53-4fb9-b85a-5fb3c7f6bb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata \n",
    "print(vertebral_column.data.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c9a09f-5c4d-4528-9937-00af88eb682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5ad73e-9178-4dd5-b861-16201d986819",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(artificial_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3d897c-e8a5-49b2-b671-4fcc6ba39acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Definindo os parâmetros para as classes artificiais\n",
    "# Classe 0: localizada abaixo e à esquerda\n",
    "class_0 = np.random.normal(loc=(-2, -2), scale=0.5, size=(50, 2))\n",
    "\n",
    "# Classe 1: localizada à direita e acima da linha, mas abaixo\n",
    "class_1 = np.random.normal(loc=(2, -2), scale=0.5, size=(50, 2))\n",
    "\n",
    "# Classe 2: localizada à direita e acima\n",
    "class_2 = np.random.normal(loc=(2, 2), scale=0.5, size=(50, 2))\n",
    "\n",
    "# Classe 3: localizada à esquerda e acima\n",
    "class_3 = np.random.normal(loc=(-2, 2), scale=0.5, size=(50, 2))\n",
    "\n",
    "# Combinando as classes\n",
    "X_artificial = np.vstack((class_0, class_1, class_2, class_3))\n",
    "y_artificial = np.array([0]*50 + [1]*50 + [2]*50 + [3]*50)\n",
    "\n",
    "# Criando um DataFrame para os dados artificiais\n",
    "artificial_data = pd.DataFrame(X_artificial, columns=['Feature1', 'Feature2'])\n",
    "artificial_data['label'] = y_artificial\n",
    "\n",
    "# Salvando os dados artificiais em um arquivo CSV\n",
    "artificial_data.to_csv('dados_artificiais_classes.csv', index=False)\n",
    "\n",
    "# Plot dos dados artificiais com as classes\n",
    "plt.scatter(X_artificial[:, 0], X_artificial[:, 1], c=y_artificial, cmap='viridis')\n",
    "plt.title(\"Dados Artificiais com 4 Classes\")\n",
    "plt.xlabel(\"Feature1\")\n",
    "plt.ylabel(\"Feature2\")\n",
    "plt.show()\n",
    "# Empilhando as classes\n",
    "data = np.vstack((class_0, class_1, class_2, class_3))\n",
    "\n",
    "# Convertendo para array NumPy (se já não estiver)\n",
    "data_array = np.array(data)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdc3fbd-e06e-47b3-bad1-3b372f6d8144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_artificial, y_artificial, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cdb62d-1799-498b-8577-fb3ec97219cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rejection costs  \n",
    "rejection_costs = [0.04, 0.12, 0.24, 0.36, 0.48] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813b72f7-2bcf-4243-ab1d-9f803caeaf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store results  \n",
    "accuracies = []  \n",
    "rejection_rates = []  \n",
    "std_accuracies = []  \n",
    "std_rejection_rates = []  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98cede3-9769-4bc5-a541-276bd89ff1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rejection_cost in rejection_costs:  \n",
    "   accuracy_list = []  \n",
    "   rejection_rate_list = []  \n",
    "   for _ in range(20):  \n",
    "      # Train and predict  \n",
    "      classifier = GaussianBayesClassifierWithRejection(rejection_cost=rejection_cost)  \n",
    "      classifier.fit(X_train, y_train)  \n",
    "      y_pred = classifier.predict(X_test)  \n",
    "  \n",
    "      # Compute accuracy and rejection rate  \n",
    "      accuracy = accuracy_score(y_test, y_pred, normalize=True)  \n",
    "      rejection_rate = np.mean(y_pred == -1)  \n",
    "  \n",
    "      accuracy_list.append(accuracy)  \n",
    "      rejection_rate_list.append(rejection_rate)  \n",
    "  \n",
    "   # Compute mean and standard deviation of accuracy and rejection rate  \n",
    "   mean_accuracy = np.mean(accuracy_list)  \n",
    "   std_accuracy = np.std(accuracy_list)  \n",
    "   mean_rejection_rate = np.mean(rejection_rate_list)  \n",
    "   std_rejection_rate = np.std(rejection_rate_list)  \n",
    "  \n",
    "   accuracies.append(mean_accuracy)  \n",
    "   rejection_rates.append(mean_rejection_rate)  \n",
    "   std_accuracies.append(std_accuracy)  \n",
    "   std_rejection_rates.append(std_rejection_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbd45a7-6de9-4370-af98-64ffa5e40d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot AR curve  \n",
    "plt.plot(rejection_costs, accuracies)  \n",
    "plt.xlabel('Rejection Cost (Wr)')  \n",
    "plt.ylabel('Accuracy')  \n",
    "plt.title('Accuracy-Rejection (AR) Curve')  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcac664-3dac-44d4-86db-4de800045f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results  \n",
    "print('Rejection Cost (Wr) | Accuracy (mean ± std) | Rejection Rate (mean ± std)')  \n",
    "for i, rejection_cost in enumerate(rejection_costs):  \n",
    "   print(f'{rejection_cost:.2f} | {accuracies[i]:.4f} ± {std_accuracies[i]:.4f} | {rejection_rates[i]:.4f} ± {std_rejection_rates[i]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ccb9ab-1577-4b97-b721-2d6e91f6683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot AR curve  \n",
    "plt.plot(rejection_costs, accuracies, 'bo-', label='Accuracy')  \n",
    "plt.fill_between(rejection_costs, [a - sa for a, sa in zip(accuracies, std_accuracies)], [a + sa for a, sa in zip(accuracies, std_accuracies)], alpha=0.2)  \n",
    "plt.plot(rejection_costs, rejection_rates, 'ro-', label='Rejection Rate')  \n",
    "plt.fill_between(rejection_costs, [r - sr for r, sr in zip(rejection_rates, std_rejection_rates)], [r + sr for r, sr in zip(rejection_rates, std_rejection_rates)], alpha=0.2)\n",
    "plt.xlabel('Rejection Cost (Wr)')  \n",
    "plt.ylabel('Taxa de Acurácia/Rejeição')  \n",
    "plt.title('Curva Acurácia-Rejeição')  \n",
    "plt.legend()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebed842a-1908-4167-9b8b-3f83b2e929f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
